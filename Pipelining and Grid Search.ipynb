{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing pipelines for data processing\n",
    "\n",
    "`sklearn.pipeline.Pipeline(steps, memory=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "                    ('pca', PCA(n_components=2)),\n",
    "                    ('clf', LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_svm = Pipeline([('scl', StandardScaler()),\n",
    "                     ('pca', PCA(n_components=2)),\n",
    "                     ('clf', svm.SVC(random_state=42))])\n",
    "\n",
    "pipe_dt = Pipeline([('scl', StandardScaler()),\n",
    "                    ('pca', PCA(n_components=2)),\n",
    "                    ('clf', tree.DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "# List of pipelines for ease of iteration\n",
    "pipelines = [pipe_lr, pipe_svm, pipe_dt]\n",
    "\n",
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "pipe_dict = {0: 'Logistic Regression', 1: 'Support Vector Machine', 2: 'Decision Tree'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the data to the pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression pipeline test accuracy: 0.933\n",
      "Support Vector Machine pipeline test accuracy: 0.900\n",
      "Decision Tree pipeline test accuracy: 0.867\n",
      "Classifier with best accuracy: Logistic Regression\n",
      "Saved Logistic Regression pipeline to file\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipelines\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "# Compare accuracies\n",
    "for idx, val in enumerate(pipelines):\n",
    "    print('%s pipeline test accuracy: %.3f' % (pipe_dict[idx], val.score(X_test, y_test)))\n",
    "\n",
    "# Identify the most accurate model on test data\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_pipe = ''\n",
    "for idx, val in enumerate(pipelines):\n",
    "    if val.score(X_test, y_test) > best_acc:\n",
    "        best_acc = val.score(X_test, y_test)\n",
    "        best_pipe = val\n",
    "        best_clf = idx\n",
    "print('Classifier with best accuracy: %s' % pipe_dict[best_clf])\n",
    "\n",
    "# Save pipeline to file\n",
    "joblib.dump(best_pipe, 'best_pipeline.pkl', compress=1)\n",
    "print('Saved %s pipeline to file' % pipe_dict[best_clf])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating pipeline with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of parameters for the decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree model hyperparameters:\n",
      " {'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': 42, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "print('Decision tree model hyperparameters:\\n', pipe_dt.steps[2][1].get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected hyperparameters for grid search\n",
    "\n",
    "* **criterion** - This is the function used to evaluate the quality of the split; we will use both options available in Scikit-learn: Gini impurity and information gain (entropy)\n",
    "\n",
    "\n",
    "* **min_samples_leaf** - This is the minimum number of samples required for a valid leaf node; we will use the integer range 1 to 5\n",
    "\n",
    "\n",
    "* **max_depth** - The is the maximum depth of the tree; we will use the integer range 1 to 5\n",
    "\n",
    "\n",
    "* **min_samples_split** - This is the minimum number of samples required in order to split a non-leaf node; we will use the integer range 1 to 5\n",
    "\n",
    "\n",
    "* **presort** - This indicates whether or not to presort the data in order to speed up the location of best splits during fitting; this does not have any effect on the resulting model accuracy (only on training times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Set grid search params\n",
    "grid_params = [{'clf__criterion': ['gini', 'entropy'],\n",
    "                'clf__min_samples_leaf': param_range,\n",
    "                'clf__max_depth': param_range,\n",
    "                'clf__min_samples_split': param_range[1:],\n",
    "                'clf__presort': [True, False]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct grid search\n",
    "gs = GridSearchCV(estimator=pipe_dt,\n",
    "                  param_grid=grid_params,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.925\n",
      "\n",
      "Best params:\n",
      " {'clf__criterion': 'gini', 'clf__max_depth': 2, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__presort': True}\n"
     ]
    }
   ],
   "source": [
    "# Fit using grid search\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing multiple models, pipelines and grid searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct some pipelines\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "                    ('clf', LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_lr_pca = Pipeline([('scl', StandardScaler()),\n",
    "                        ('pca', PCA(n_components=2)),\n",
    "                        ('clf', LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_rf = Pipeline([('scl', StandardScaler()),\n",
    "                    ('clf', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "pipe_rf_pca = Pipeline([('scl', StandardScaler()),\n",
    "                        ('pca', PCA(n_components=2)),\n",
    "                        ('clf', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "pipe_svm = Pipeline([('scl', StandardScaler()),\n",
    "                     ('clf', svm.SVC(random_state=42))])\n",
    "\n",
    "pipe_svm_pca = Pipeline([('scl', StandardScaler()),\n",
    "                         ('pca', PCA(n_components=2)),\n",
    "                         ('clf', svm.SVC(random_state=42))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the grid search parameters for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "param_range_fl = [1.0, 0.5, 0.1]\n",
    "\n",
    "grid_params_lr = [{'clf__penalty': ['l1', 'l2'],\n",
    "                   'clf__C': param_range_fl,\n",
    "                   'clf__solver': ['liblinear']}] \n",
    "\n",
    "grid_params_rf = [{'clf__criterion': ['gini', 'entropy'],\n",
    "                   'clf__min_samples_leaf': param_range,\n",
    "                   'clf__max_depth': param_range,\n",
    "                   'clf__min_samples_split': param_range[1:]}]\n",
    "\n",
    "grid_params_svm = [{'clf__kernel': ['linear', 'rbf'], \n",
    "                    'clf__C': param_range}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = -1\n",
    "\n",
    "gs_lr = GridSearchCV(estimator=pipe_lr,\n",
    "                     param_grid=grid_params_lr,\n",
    "                     scoring='accuracy',\n",
    "                     cv=10) \n",
    "\n",
    "gs_lr_pca = GridSearchCV(estimator=pipe_lr_pca,\n",
    "                         param_grid=grid_params_lr,\n",
    "                         scoring='accuracy',\n",
    "                         cv=10)\n",
    "\n",
    "gs_rf = GridSearchCV(estimator=pipe_rf,\n",
    "                     param_grid=grid_params_rf,\n",
    "                     scoring='accuracy',\n",
    "                     cv=10, \n",
    "                     n_jobs=jobs)\n",
    "\n",
    "gs_rf_pca = GridSearchCV(estimator=pipe_rf_pca,\n",
    "                         param_grid=grid_params_rf,\n",
    "                         scoring='accuracy',\n",
    "                         cv=10, \n",
    "                         n_jobs=jobs)\n",
    "\n",
    "gs_svm = GridSearchCV(estimator=pipe_svm,\n",
    "                      param_grid=grid_params_svm,\n",
    "                      scoring='accuracy',\n",
    "                      cv=10,\n",
    "                      n_jobs=jobs)\n",
    "\n",
    "gs_svm_pca = GridSearchCV(estimator=pipe_svm_pca,\n",
    "                          param_grid=grid_params_svm,\n",
    "                          scoring='accuracy',\n",
    "                          cv=10,\n",
    "                          n_jobs=jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = [gs_lr, gs_lr_pca, gs_rf, gs_rf_pca, gs_svm, gs_svm_pca]\n",
    "\n",
    "\n",
    "grid_dict = {0: 'Logistic Regression', 1: 'Logistic Regression w/PCA', \n",
    "             2: 'Random Forest', 3: 'Random Forest w/PCA', \n",
    "             4: 'Support Vector Machine', 5: 'Support Vector Machine w/PCA'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the grid search objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model optimizations...\n",
      "\n",
      "Estimator: Logistic Regression\n",
      "Best params: {'clf__C': 1.0, 'clf__penalty': 'l1', 'clf__solver': 'liblinear'}\n",
      "Best training accuracy: 0.917\n",
      "Test set accuracy score for best params: 0.967 \n",
      "\n",
      "Estimator: Logistic Regression w/PCA\n",
      "Best params: {'clf__C': 0.5, 'clf__penalty': 'l1', 'clf__solver': 'liblinear'}\n",
      "Best training accuracy: 0.858\n",
      "Test set accuracy score for best params: 0.933 \n",
      "\n",
      "Estimator: Random Forest\n",
      "Best params: {'clf__criterion': 'gini', 'clf__max_depth': 3, 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 2}\n",
      "Best training accuracy: 0.942\n",
      "Test set accuracy score for best params: 1.000 \n",
      "\n",
      "Estimator: Random Forest w/PCA\n",
      "Best params: {'clf__criterion': 'entropy', 'clf__max_depth': 5, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 3}\n",
      "Best training accuracy: 0.917\n",
      "Test set accuracy score for best params: 0.900 \n",
      "\n",
      "Estimator: Support Vector Machine\n",
      "Best params: {'clf__C': 3, 'clf__kernel': 'linear'}\n",
      "Best training accuracy: 0.967\n",
      "Test set accuracy score for best params: 0.967 \n",
      "\n",
      "Estimator: Support Vector Machine w/PCA\n",
      "Best params: {'clf__C': 4, 'clf__kernel': 'rbf'}\n",
      "Best training accuracy: 0.925\n",
      "Test set accuracy score for best params: 0.900 \n",
      "\n",
      "Classifier with best test set accuracy: Random Forest\n",
      "\n",
      "Saved Random Forest grid search pipeline to file: best_gs_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "print('Performing model optimizations...')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grids):\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\t\n",
    "    # Fit grid search\n",
    "    gs.fit(X_train, y_train)\n",
    "    # Best params\n",
    "    print('Best params: %s' % gs.best_params_)\n",
    "    # Best training data accuracy\n",
    "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(X_test)\n",
    "    # Test data accuracy of model with best params\n",
    "    print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
    "    # Track best (highest test accuracy) model\n",
    "    if accuracy_score(y_test, y_pred) > best_acc:\n",
    "        best_acc = accuracy_score(y_test, y_pred)\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "print('\\nClassifier with best test set accuracy: %s' % grid_dict[best_clf])\n",
    "\n",
    "# Save best grid search pipeline to file\n",
    "dump_file = 'best_gs_pipeline.pkl'\n",
    "joblib.dump(best_gs, dump_file, compress=1)\n",
    "print('\\nSaved %s grid search pipeline to file: %s' % (grid_dict[best_clf], dump_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
